general_cfg:
  algo_name: PPO
  env_name: gym 
  device: cpu 
  mode: train 
  load_checkpoint: false 
  load_path: Train_CartPole-v1_PPO_20231225-124842 # if load checkpoint, then config path in 'tasks' dir
  load_model_step: best 
  n_interactors: 1
  max_episode: -1
  max_step: 200 
  seed: 1 
  online_eval: true 
  online_eval_episode: 10 
  model_save_fre: 100 
  policy_summary_fre: 2
  exps_trucation_size: 20
algo_cfg:
  ppo_type: clip
  learn_frequency: 20 
  independ_actor: true
  share_optimizer: false
  actor_merge_layers:
    - layer_type: linear
      layer_size: [256]
      activation: relu
    - layer_type: linear
      layer_size: [256]
      activation: relu
  critic_merge_layers:
    - layer_type: linear
      layer_size: [256]
      activation: relu
    - layer_type: linear
      layer_size: [256]
      activation: relu
  buffer_type: REPLAY_QUE
  max_buffer_size: 2000
  actor_lr: 0.0003
  critic_lr: 0.001
  entropy_coef: 0.01
  eps_clip: 0.2
  gamma: 0.99
  k_epochs: 1
  batch_size: 256
  sgd_batch_size: 256
env_cfg:
  id: CartPole-v1
  render_mode: null
  
