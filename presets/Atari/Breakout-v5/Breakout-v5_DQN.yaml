general_cfg:
  algo_name: DQN # algo name
  env_name: gym # env name, differ from env_id in env_cfgs
  device: cuda # device, cpu or cuda
  mode: train # run mode: train, test
  collect_traj: false # if collect trajectories or not
  mp_backend: single # multi-processing mode: single(default), ray
  n_workers: 2 # number of workers if using multi-processing, default 1
  load_checkpoint: false # if load checkpoint or not
  load_path: Train_single_CartPole-v1_DQN_20230515-211721 # if load checkpoint, then config path in 'tasks' dir
  load_model_step: best # load model step
  max_episode: 300 # max episodes, set -1 to keep running
  max_step: 500 # max steps per episode
  seed: 1 # random seed, set 0 not to use seed
  online_eval: true # if online eval or not
  online_eval_episode: 10 # online eval episodes
  model_save_fre: 500 # update step frequency of saving model
algo_cfg:
  value_layers:
    - layer_type: conv2d
      in_channel: 4
      out_channel: 32
      kernel_size: 8
      stride: 4
      activation: relu
    - layer_type: conv2d
      in_channel: 32
      out_channel: 64
      kernel_size: 4
      stride: 2
      activation: relu
    - layer_type: conv2d
      in_channel: 64
      out_channel: 64
      kernel_size: 3
      stride: 1
      activation: relu
    - layer_type: flatten
    - layer_type: linear
      layer_size: [512] 
      activation: relu
  batch_size: 64
  buffer_type: REPLAY_QUE
  buffer_size: 100000
  epsilon_decay: 500
  epsilon_end: 0.01
  epsilon_start: 0.95
  gamma: 0.95
  lr: 0.0001
  target_update: 4
env_cfg:
  id: ALE/Breakout-v5
  wrapper: envs.wrappers.AtariWrapper
  render_mode: null